\documentclass{article}

%%%%%%%% SKYEPAPHORA %%%%%%%%
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{setspace}
\usepackage{listings}
\usepackage{multicol}
\usepackage{textcomp}
\usepackage{centernot}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    linkcolor=blue
    }

\geometry{letterpaper,
          left = 25.4mm,
          right = 25.4mm,
          bottom = 25.4mm,
          top = 25.4mm}

\setlength{\fboxsep}{8pt}
% \setlength{\parindent}{0pt}

\newcommand{\define}{\ensuremath \stackrel{\text{def}}{=}}
\newcommand{\Var}{\ensuremath \text{Var}}
\newcommand{\Cov}{\ensuremath \text{Cov}}
\newcommand{\E}{\ensuremath \text{E}}
\newcommand{\myrule}{\rule{\linewidth}{0.5pt}}

\definecolor{gold}{HTML}{A05000}
\definecolor{redd}{HTML}{C00000}
\definecolor{bluu}{HTML}{0000C0}
\definecolor{gren}{HTML}{00B000}

\definecolor{salt}{HTML}{FBFAF9}
\definecolor{pepper}{HTML}{251F18}

\begin{document}
\pagecolor{salt}\color{pepper}
{\noindent\Huge\textbf{Proposal}}

%% --- SECTION 1 ------------ %%
\section{Other Subclassifications of Non-Stationarity: \\ 
Departures from UMPs}
    
So far, we've discussed the motivations and techniques behind estimating the modulating function $c(t)$ in uniformly modulated processes of the form $X(t) = c(t)Y(t)$, where $Y(t)$ is stationary. 
\begin{itemize}
    \item Continue with motivations and a summary of upcoming sections
\end{itemize}

\subsection{Generalized Uniformly Modulated Processes}
A natural first step in generalizing the established UMP framework would be to consider linear combinations of $k$ many UMPs, where $k$ is some integer.\footnote{Practically speaking, as $k$ becomes large, it may no longer be worth classifying $X(t)$ as a GUMP. An exception might include applications whose processes are expected to be some linear combinations of UMPs for one reason or another. The analysis of compounded seismic waves [??], for example.} Begin by defining the process
\begin{flalign}
    X(t) &= X_1(t) + X_2(t) + \dots + X_k(t)
\intertext{where each $X_j$ time series represents a UMP:}
    X_j(t)  &= c_j(t)Y_j(t) \qquad 1 \leq j \leq k
\end{flalign}
This implies each $Y_j(t)$ is stationary, and that each corresponding modulating function $c_j(t)$ is non-negative with a Fourier transform maximized at zero.  

I propose we call $X(t)$ a \textit{Generalized} Uniformly Modulated Process of order $k=2$. We will abbreviate this to GUMP-$k$ for the remainder of this document, and will refer to the $X_j$ as UMP \textit{components} of $X$.
% Jointly???    JUMPS
% Compound???   CUMPS   (combined? composite?)
% Multi???      MUMPS   (mixed?)
% Layered???    LUMPS
% Hybrid???     HUMPS
% Generalized?? GUMPS!!!!!!!!!

\subsubsection{Estimating GUMP-2 Evolutionary Spectra}
Let $X(t)$ be a GUMP-2 with component UMPs $\{X_j\}_{j=1,2}$.
% Let $k=2$, then take $X$ and the $\{X_j\}$ as they're defined in equations (??) and (??), so that $X$ is a GUMP-2 with UMP components $X_1$ and $X_2$. 
It's known [Priestly '65, except actually I think it's '81] that the time-frequency spectra of the component UMPs are given by
\begin{flalign}
    S_{X_j}(t,f) &= c_j^2(t)S_{Y_j}(f) 
\intertext{The representation in (??) comes from Priestley's definition of evolutionary power spectra for \textit{oscillatory} processes: a more general class which, as the reader may recall from chapter 2, includes UMPs.\footnote{Note that the TFS matrices we describe reduce Priestley's EPS from the continuous-time to the discrete-time case.} It's tempting to imagine that a similar derivation applies to the TFS matrix of $X(t)$. As we'll see, this is not so obvious.} \notag \\[-28pt]
\intertext{\indent The spectral representation of the stationary time series $Y_j(t)$ is given by}
    Y_j(t) &= \int_{\mathcal{D}_f} e^{i2\pi ft} dZ_{Y_j}(f), 
\intertext{where $\mathcal{D}_f$ denotes the frequency interval $[-1/2,1/2],$ upon which the orthogonal increment processes $dZ_{Y_j}$ each satisfy}
    \E \Big[|dZ_{Y_j}|^2\Big] &= S_{Y_j}(f)df.
\end{flalign}
The representation (??) may be substituted into the expanded expression for the GUMP-2:
\begin{flalign}
    X(t)    &=  c_1(t)Y_1(t) + c_2(t)Y_2(t) \\[3pt]
            &=  \int_{\mathcal{D}_f} c_1(t)e^{i2\pi ft} dZ_{Y_1}(f) + 
                \int_{\mathcal{D}_f} c_2(t)e^{i2\pi ft} dZ_{Y_2}(f),
\end{flalign}
and it's here where things start to become complicated. We wish to define the evolutionary power spectrum of $X(t)$ via its relation to the GUMP's variance. By the properties of variance for linear combinations of complex random variables, the variance of $X(t)$ is given by
{\small\begin{flalign}
    \Var\big[X(t)\big] 
    &=  \int_{\mathcal{D}_f} 
            \Big(|c_1(t)|^2 S_{Y_1}(f) + |c_2(t)|^2 S_{Y_2}(f)\Big)df +
        \int_{\mathcal{D}_f} \int_{\mathcal{D}_f} 
            2c_1(t)c_2(t)
            e^{i2\pi ft}e^{-i2\pi f't}
            \Cov \Big[dZ_{Y_1}(f),dZ_{Y_2}(f')\Big] && \notag \\[10pt]
    &=  \int_{\mathcal{D}_f} 
            \Big(|c_1(t)|^2 S_{Y_1}(f) + 
            |c_2(t)|^2 S_{Y_2}(f)\Big)df +  
        \int_{\mathcal{D}_f} \int_{\mathcal{D}_f} 
            2c_1(t)c_2(t)
            e^{i2\pi (f-f')t}
            \E \Big[dZ_{Y_1}(f)dZ_{Y_2}^*(f')\Big]. &&
\end{flalign}}
Conveniently, by [B\& D: section 11.8, also p450 of pdf], the orthogonal increments processes in (??) satisfy
\begin{equation}
    \E \Big[dZ_{Y_1}(f)dZ_{Y_2}^*(f')\Big] = 0 \qquad \text{for } f \neq f'.
\end{equation}
When $f=f'$, however, we're left with the \textit{cross spectrum} of $Y_1$ and $Y_2$, which we denote $S_{Y_1,Y_2}(f)$. Finally,
\begin{flalign}
    \Var\big[X(t)\big]
        &=  \int_{\mathcal{D}_f} 
                \Big(|c_1(t)|^2 S_{Y_1}(f) + 
                |c_2(t)|^2 S_{Y_2}(f) +  
                2c_1(t)c_2(t)
                S_{Y_1,Y_2}(f)
            \Big)df.
    \intertext{For now, we propose an expression for the evolutionary power spectrum of $X(t)$ given by}
    S^E_X(t,f)
        &= |c_1(t)|^2 S_{Y_1}(f) + 
                |c_2(t)|^2 S_{Y_2}(f) +  
                2c_1(t)c_2(t)
                S_{Y_1,Y_2}(f),
\end{flalign}
following the logic which motivated [Priestley '65?]'s definition of the EPS for oscillatory processes. Note that this definition uses both continuous time \textit{and} continuous frequency, but that the corresponding TFS matrix $\mathbb{S}_X$ will discretize this to a set of $N$ time points and $N_f$ Fourier frequencies.

\subsubsection{GUMP-2 detection}
\textit{INTRO blablabla}

Here, we jump carefully into some matrix notation. For $j=1,2$, define the following row vectors,
\begin{flalign}
        \vec S_{Y_j}     &= \Big[S_{Y_j}(f_1), \dots, S_{Y_j}(f_{N_f})\Big] \\
        \vec S_{Y_1,Y_2} &= \Big[S_{Y_1,Y_2}(f_1), \dots, S_{Y_1,Y_2}(f_{N_f})\Big].
    \intertext{Then define the column vectors}
        \vec g_{i,j}     &= \Big[c_i(0)c_j(0),\; c_i(1)c_j(1),\; \dots, c_i(N)c_j(N)\Big]^T
\end{flalign}
Where $i \in \{1,2\}$ may or may not be equal to $j$. Then $\mathbb{S}_X$ can be expressed:
\begin{flalign}
    \mathbb{S}_X 
    &= \vec g_{1,1} \vec S_{Y_1} + \vec g_{2,2} \vec S_{Y_2} + \vec g_{1,2} \vec S_{Y_1,Y_2} \\
    &= \mathbb{S}_{X_1} + \mathbb{S}_{X_2} + \vec g_{1,2} \vec S_{Y_1,Y_2}
\end{flalign}

Recall that since the $X_j$ are UMPs, their corresponding TFS matrices $\mathbb S_{X_j}$ each have rank 1. By a similar argument, the term  $\vec g_{1,2} \vec S_{Y_1,Y_2}$ must also be a rank 1 matrix, since we already see its decomposition as a $N\times 1$ vector times a $1 \times N_f$ vector. Therefore, $\mathbb{S}_X$ itself must have rank $\leq 3$, by subadditivity.

Unlike the case of simple UMPs, however, the log-TFS matrix of GUMP-2 is not easily broken down. It's true that $\log\mathbb{S}_{X_j}$ has rank $\leq 2$ since we constructed the $X_j$ to be UMPs, but unless these TFS matrices can be identified, there is not much we can gather about the logarithmic properties of the greater $\mathbb S_X$ matrix.   


%%%                                                                                    %%%
%%% ------------ SKYE YOU CAN START HERE IF YOU WANT TO WORK ON CHAPTER 4 ------------ %%%
%%%                                                                                    %%%

\subsubsection{Estimating $c_1, c_2$ via singular value decomposition of GUMP-2 TFS matrices}
\begin{itemize}
    \item See if SVD of GUMP-2 TFS gives you anything useful, parallel p.80 (pdf) of Azadeh if you need a guide
    \item look into Dave's work on cross spectra if you can, or maybe B\&D. Get an intuition.
    \item read up on evol cross spectra, start with paper from Glen (it's in Slack if you can't find it), take notes
\end{itemize}

\newpage
\noindent{\LARGE \textbf{Notes for Section 1}}
\section*{June $15^{th}$}
\begin{itemize}
    \item would C be the 2 left eigens of SVD, S be the 2 right vectors?
    \item plot eigenvals... if there's a dropoff, 
        use that to determine rank when there's noise in the way
    \item construct nonstationary process:
    \begin{itemize}
        \item 2 indep stationary processes
        \item take lin  combo at time t
        \item 2 weights: w1 at t, w2 at t (these are absorbed by c(t))
        \item as t varies, the weights vary
        \item contributions from the 2 independent seris will differ over time
        \item thus it won't be stationary
    \end{itemize}
    \item now we want to estimate the weight function as a function of time
    \item  EPS gives us info about covariance kernel, which gives us info about weight function. Possibly?
\end{itemize}
\section*{June $22^{nd}$}
\begin{itemize}
    \item Interested in: Sum of 2 TFS matrices $\to$ 2 non-negligible singular  
        values (SV) in SVD
    \item Formal (non-graphical) test for SV: quantify dropoff for SV when sorted   
        in descending order. Come up with some ad-hoc rule, maybe.
    \item Consider $k$ non-zero SVs as an indicator of k-order GUMPs. (that is, a 
        linear combo of $k$ UMPs).
    \begin{itemize}
        \item Use these first $k$ terms to model most of the variation in $X$.
    \end{itemize}
    \item Check if resulting TFS has entries $S_X(t,f) = c_1^2(t)S_{Y_1}(f) + c_2^2(t)S_{Y_2}(f)$. If so:
    \begin{itemize}
        \item Estimate of mod funcs $c_1, c_2$ should be proportional to left-eigenvectors of $\hat S_X$, A.K.A the first two columns $U_1$ and $U_2$ of $U$ in the SVD $UDV^T$.
        \item Akin to the rowsum approach for $k=1,$ there are potentially $2(N+N_f)$ unknowns and $2(N+N_f)$ equations. $N$ each for $c_1$ and $c_2$, then $N_f$ each for $S_{Y_1}$ and $S_{Y_2}$.
        \item for $k>2$ this continues, with the number of unknowns being $k(N+N_f)$
    \end{itemize}
    \item Consider a high-frequency $c_1$ and a low frequency $c_2$\footnote{Okay but by definition the modulating function (not just for UMPs but for oscillatory functions in general) needs to have a Fourier transform whose modulus is maximized at zero. So these freqs have all gotta be real slow if we're using the traditional definition of a modulating function, here.}
    \item Characterization of near-UMPs: how close are TFS eigenvals to zero? Can this classify ``how" UMP something is?
\end{itemize}
\subsubsection*{Glen's proposed estimation algorithm: here I use $Z$ for lin combo of UMPs}
\begin{itemize}
    \item Say you've estimated $S_{Y_1}, S_{Y_2}$. Invert these to get time-domain estimates $\hat Y_1(t)$ and $\hat Y_2(t)$.
    \item So like, 
        $\hat X(t) = \hat c_1(t)\hat Y_1(t) + \hat c_2(t)\hat Y_2(t)$ \\
    \item Solve for $\hat Y_1$ in above equation and call it $\tilde Y_1$
    \item So like, 
        $\tilde Y_1 = \big(\hat X(t) - \hat c_2(t)\hat Y_2(t)\big)/\hat c_1(t)$
    \item compare spectra of $\tilde Y_1$ and $\hat Y_1$\\
    \item repeat for $\tilde Y_2$
    \item if spectra improve, plug $\tilde Y_1$ and $\tilde Y_2$ in for $\hat Y_1$ and $\hat Y_2$.\\
    \item Use $2N$ equations and $2N$ unknowns to estimate $c_1, c_2$ similarly to UMP case. Call these $\tilde c_1, \tilde c_2$.
    \item New estimate of $Z$ becomes 
        $\tilde X(t) = \tilde c_1(t)\tilde Y_1(t) + \tilde c_2(t)\tilde Y_2(t)$
    \item iterate to improve estimates of $c_1, c_2$ and/or $Y_1, Y_2$
\end{itemize}
\subsubsection*{Other departures from UMPs}
\begin{itemize}
    \item UMP + line component. (Make this a whole section - maybe subsection - at the very beginning of proposal chapter)
    \begin{itemize}
        \item What does TFS look like? 
        \item Can we still estimate $c$?
        \item Does harmonic F-test fail when trying to identify line components? It will probably detect them but with splitting: $f \pm f_0$, due to exponents in fourier transform
        \item squared cosine provides a (non-negative!) modulating function but will increase splitting 2-fold.
        \item by generalizing $X(t)$ from stationary to UMP, can we get better estimate of line components in this case?
    \end{itemize}
\end{itemize}

%% --- SECTION 2 ------------ %%
\section{Evolutionary Cross-Spectra and Coherence}

%% --- SECTION 3 ------------ %%
\section{Multitaper Analysis of Blind Source Separation (BSS) Signals}
\begin{itemize}
    \item Discuss: how might multitaper benefit BSS? 
\end{itemize}

%% --- SECTION 4 ------------ %%
\section{Analysis of Non-Stationary Data}
    \begin{itemize}
        \item EEG
        \item BSS data
        \item Seismic data (pretty ump by nature)
    \end{itemize}

\end{document}